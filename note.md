### Jacobian Weighting in downsampling
The paper suggest that weight the sample using a modified Jacobian so that there is less weight for samples near corners and edges.
The Jacobian is $J(x,y,z) = \frac{1}{(x^2+y^2+z^2)^{\frac{3}{2}}}$. This Jacobian makes sense since if the sample is near corner or edges. The sum of $x^2,y^2,z^2$ would be larger so that the Jacobian is smaller.
However, the code they use the weight of $(x^2+y^2+z^2)^{\frac{3}{2}}$, so the samples near corners and edges have larger weights. This seems contradictory to what the authors state in the paper.

#### About Jacobian
- $ x = 2u $ and $J(u) = \frac{dx}{du} = 2$. This means change of u in one unit causes the change of x in 2 unit
- So for cube mapping to sphere unit direction $r(x,y,z) = \frac{(x,y,z)}{\sqrt{x^2+y^2+z^2}}$
  - $J(x,y,z) = \frac{1}{(x^2 + y^2 + z^2)^{\frac{3}{2}}}$. This means change of cube texture at the center of cube face cause the same amount of change to the sphere surface. But change in the corner/edges part result in less change for sphere surface(there is a compression in volume)
  - In reverse, a change on sphere surface will result in a larger change in cube texture.
    - This is why in the second pass filtering, the code uses a larger miplevel for directions that are near corners and edges.
      - The code add a miplevel of $\frac{1}{2} \log_{2}{(\frac{1}{J(x,y,z)})}$
      - >The sampling function applies a mip-level offset that is a function of the sampling position and adjusts for the Jacobian of the sphere to cube mapping. This offset is simply the contribution of the Jacobian factored out of Equation 4.



### Filtering computation
- Frames
  - Three frames, along x,y,z axis. Think of this as moving Z axis(the UP vector) to either $(1,0,0),(0,1,0)$ or $(0,0,1)$
  - Change of coordinate system for later polynomial fit and parameter computation
    - The texel direction $(x,y,z)$ is considered the new $Z$ axis, so $\vec{Z} = (x,y,z)$. The polar axis of this direction(which face is this dir on) is $\vec{n}$. Then the new x-axis would be $\vec{X} = \vec{n} \times \vec{Z}$. The new Y axis would be $\vec{(x,y,z)} \times \vec{X}$
    - The offset is computed using this new parameterization. $x_i\vec{X} + y_i\vec{Y} + z_i\vec{Z}$
    - Did they do this because some kind of symmetric properties?
- $\theta$ and $\phi$ parameterization for polynomial fit
  - $\theta$ and $\phi$ are more like a modified $u,v$ parameterization where $u,v$ need special handling at $\pm Z$ faces(the up vector)
  - Note: here we use the traditional coordinate system where Z is up, not like in graphics where Z is front/back.
    - For non-up and non-bottom face.(the left right front back) face. Either $x$ or $y$ is $\pm1$. The $\theta$ would be $\pm x$ or $\pm y$ which is non-$\pm 1$(there is $\pm$ because $\theta$ goes counter-clockwise in each face, there are two faces that $x/y$ have the same order as $\theta$, the order of other two faces are reversed)
    - For up/bot face, the $\phi$ is computed as $\pm MAX(x,y)$ and $\theta$ is divided to four parts from the face origin evenly, and the point is _normalized_ to the edge and then the $\theta$ is computed as it is on the four non-up/bot face
- SampleLevel
  - The mipmap level that is generated by the polynomial could be out of bounds. A normal shader will generally clamp this to a valid range. Is this expected???